run_id: comparative-1-iter1-Qwen3-0.6B-gsm8k
method: comparative-1  # model-level SKETCH-ALIGN controller
model:
  name: Qwen3-0.6B
  num_layers: 32
  hidden_size: 4096
  gradient_checkpointing: false
  dtype: fp16
  init_seed: 42

sketch_align:               # SKETCH-ALIGN settings (enabled here)
  sketch_size: 4096         # floats in global sketch
  beta_ema: 0.98
  clamp_min: 0.3
  clamp_max: 1.7
  ema_loss_entropy_grad: true
  enable_layer_groups: false   # operates on full model fingerprint
  enabled: true
blade:
  enabled: false

# ------------------------------------------------------------------
dataset:
  name: gsm8k
  hf_subset: main
  train_split: train
  validation_split: test
  max_seq_length: 1024
  remove_whitespace: true
  prompt_format: "gsm8k_cot"
  pad_to_max: false
  shuffle_seed: 1234

training:
  num_epochs: 3
  effective_batch_size: 64
  per_device_batch_size: 8
  gradient_accumulation_steps: 8
  fp16: true
  max_grad_norm: 1.0
  seed: 42
  dataloader_num_workers: 4
  logging_steps: 10
  save_strategy: epoch
  evaluation_strategy: epoch
  optimizer:
    name: adamw
    betas: [0.9, 0.999]
    eps: 1.0e-08
    weight_decay: 0.01
  lr_scheduler:
    name: linear
    peak_lr: 5.0e-5
    warmup_steps: 50
    final_lr_ratio: 0.0
  gradient_checkpointing: false
  torch_compile: false

evaluation:
  metrics:
    - exact_match
  compute_test_set: true
  load_best_at_end: true

hardware:
  accelerator: gpu
  gpu_type: A100
  gpu_memory_gb: 80

optuna:
  n_trials: 20
  direction: maximize
  search_space:
    sketch_align.sketch_size:
      type: categorical
      choices: [1024, 2048, 4096, 8192]
    sketch_align.beta_ema:
      type: uniform
      low: 0.95
      high: 0.995
    sketch_align.clamp_min:
      type: uniform
      low: 0.1
      high: 0.5
    sketch_align.clamp_max:
      type: uniform
      low: 1.3
      high: 2.0
    training.lr_scheduler.peak_lr:
      type: loguniform
      low: 1.0e-5
      high: 1.0e-4
    training.gradient_accumulation_steps:
      type: categorical
      choices: [4, 8, 16]
