{
  "summary": {
    "_runtime": 6207.799313184,
    "_step": 348,
    "_timestamp": 1763465871.4214602,
    "_wandb": {
      "runtime": 6207
    },
    "best_epoch": 0,
    "best_val_exact_match": 0,
    "epoch": 2,
    "eval/exact_match": 0,
    "eval/loss": "NaN",
    "lr": 4.4591651542649734e-05,
    "optuna_best_params": {},
    "predictions": {
      "_type": "large-array",
      "value": []
    },
    "test_exact_match": 0,
    "train/entropy": 0,
    "train/loss": "NaN"
  },
  "config": {
    "mode": "full",
    "blade": {
      "k_bits": 16,
      "enabled": true,
      "beta_ema": 0.98,
      "clamp_max": 1.7,
      "clamp_min": 0.3,
      "indices_seed": 13,
      "implementation": "torch_hook",
      "enable_reservoir": true,
      "compute_overhead_ms": 0.05,
      "grad_sign_storage_bytes": 64,
      "share_global_multiplier": true,
      "reservoir_refresh_interval": 100
    },
    "model": {
      "name": "Qwen/Qwen3-0.6B",
      "dtype": "fp16",
      "init_seed": 42,
      "num_layers": 32,
      "hidden_size": 4096,
      "gradient_checkpointing": false
    },
    "wandb": {
      "mode": "online",
      "entity": "gengaru617-personal",
      "project": "2025-11-18"
    },
    "method": "proposed",
    "optuna": {
      "n_trials": 0,
      "direction": "maximize",
      "search_space": {
        "blade.k_bits": {
          "type": "categorical",
          "choices": [
            8,
            16,
            32
          ]
        },
        "blade.beta_ema": {
          "low": 0.95,
          "high": 0.995,
          "type": "uniform"
        },
        "blade.clamp_max": {
          "low": 1.3,
          "high": 2,
          "type": "uniform"
        },
        "blade.clamp_min": {
          "low": 0.1,
          "high": 0.5,
          "type": "uniform"
        },
        "training.lr_scheduler.peak_lr": {
          "low": 1e-05,
          "high": 0.0001,
          "type": "loguniform"
        },
        "blade.reservoir_refresh_interval": {
          "type": "categorical",
          "choices": [
            50,
            100,
            200
          ]
        },
        "training.gradient_accumulation_steps": {
          "type": "categorical",
          "choices": [
            4,
            8,
            16
          ]
        }
      }
    },
    "run_id": "proposed-iter1-Qwen3-0.6B-gsm8k",
    "dataset": {
      "name": "gsm8k",
      "hf_subset": "main",
      "pad_to_max": false,
      "train_split": "train",
      "shuffle_seed": 1234,
      "prompt_format": "gsm8k_cot",
      "max_seq_length": 1024,
      "validation_split": "test",
      "remove_whitespace": true
    },
    "hardware": {
      "gpu_type": "A100",
      "accelerator": "gpu",
      "gpu_memory_gb": 80
    },
    "training": {
      "fp16": true,
      "seed": 42,
      "optimizer": {
        "eps": 1e-08,
        "name": "adamw",
        "betas": [
          0.9,
          0.999
        ],
        "weight_decay": 0.01
      },
      "num_epochs": 3,
      "lr_scheduler": {
        "name": "linear",
        "peak_lr": 5e-05,
        "warmup_steps": 50,
        "final_lr_ratio": 0
      },
      "logging_steps": 1,
      "max_grad_norm": 1,
      "save_strategy": "epoch",
      "torch_compile": false,
      "evaluation_strategy": "epoch",
      "effective_batch_size": 64,
      "per_device_batch_size": 8,
      "dataloader_num_workers": 4,
      "gradient_checkpointing": false,
      "gradient_accumulation_steps": 8
    },
    "evaluation": {
      "metrics": [
        "exact_match"
      ],
      "compute_test_set": true,
      "load_best_at_end": true
    },
    "results_dir": ".research/iteration1",
    "sketch_align": {
      "enabled": false
    }
  }
}